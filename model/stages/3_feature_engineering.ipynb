{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import dependencies",
   "id": "fd6288d414c9adfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T15:27:36.889988Z",
     "start_time": "2024-11-13T15:27:36.524598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Manipulations and Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tuning & Splitting Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Services\n",
    "import services.ModelStageService as sds\n",
    "\n",
    "# utils\n",
    "import datetime\n",
    "import utils.EDAUtils as edaUtils\n",
    "import utils.ModelTrainingAndEvaluationUtils as mteUtils\n",
    "import utils.DataTransformationUtils as dtUtils\n",
    "import utils.PlottingUtils as pltUtils\n",
    "\n",
    "\n",
    "stage_data_io_service = sds.ModelStageService(previous_stage_name=sds.PREPROCESSING_STAGE, current_stage_name=sds.FEATURE_ENGINEERING_STAGE)"
   ],
   "id": "fcff937794ab8a13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6313725490196078, 0.788235294117647, 0.9568627450980393),\n",
       " (1.0, 0.7058823529411765, 0.5098039215686274),\n",
       " (0.5529411764705883, 0.8980392156862745, 0.6313725490196078),\n",
       " (1.0, 0.6235294117647059, 0.6078431372549019),\n",
       " (0.8156862745098039, 0.7333333333333333, 1.0),\n",
       " (0.8705882352941177, 0.7333333333333333, 0.6078431372549019),\n",
       " (0.9803921568627451, 0.6901960784313725, 0.8941176470588236),\n",
       " (0.8117647058823529, 0.8117647058823529, 0.8117647058823529),\n",
       " (1.0, 0.996078431372549, 0.6392156862745098),\n",
       " (0.7254901960784313, 0.9490196078431372, 0.9411764705882353)]"
      ],
      "text/html": [
       "<svg  width=\"550\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#a1c9f4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ffb482;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#8de5a1;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff9f9b;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d0bbff;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#debb9b;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fab0e4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#cfcfcf;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fffea3;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#b9f2f0;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "24006fbcfc549b09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reading text from txt file\n",
    "df = stage_data_io_service.run_or_load_stage_data(reload_stage=False)"
   ],
   "id": "e3c3f0fab4cb5dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Engineering and Data Processing for Model Building",
   "id": "be0081a88e90ef2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adding Synthetic Replenishment Data for Accurate Calculation of Credit Debt Repayment Stability (CDRS) Ratio\n",
    "\n",
    "Before calculating the Credit Debt Repayment Stability (CDRS) ratio, it is crucial to account for all transactions affecting the available balance, especially replenishments. However, the dataset lacks direct information on replenishment transactions, except for specific cases like reversal transactions. This absence introduces potential inaccuracies when calculating repayment stability.\n",
    "\n",
    "To resolve this issue without altering the data schema by adding new markers, we will synthetically generate missing replenishment transactions. The approach works as follows:\n",
    "\n",
    "1. **Data Grouping and Sorting**: We group the transactions by account number and arrange them in chronological order to establish a clear transaction flow.\n",
    "   \n",
    "2. **Pairwise Transaction Comparison**: After sorting, we compare each transaction with the preceding one. If the available balance of the current transaction exceeds that of the previous one and the previous transaction is not classified as a reversal or address verification, we infer that a replenishment transaction was missing between the two.\n",
    "\n",
    "3. **Synthetic Replenishment Insertion**: For each identified gap, a synthetic replenishment transaction is inserted with a calculated amount and timestamp. This ensures that all changes in the available balance are accurately reflected in the dataset, allowing for a more precise calculation of the CDRS ratio.\n",
    "\n",
    "By synthesizing replenishment data in this way, we can achieve a more accurate and realistic assessment of credit debt \n",
    "repayment behavior without distorting the original dataset's structure.\n"
   ],
   "id": "77dbde257801151f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_skipped_replenishment_transactions(df):\n",
    "    \"\"\"\n",
    "    Adds synthetic replenishment transactions to a DataFrame of financial transactions.\n",
    "\n",
    "    The method processes transaction data for each account, ensuring replenishment transactions \n",
    "    are inserted when missing. It works by grouping transactions by account number, \n",
    "    sorting them chronologically, and checking if a replenishment transaction is needed \n",
    "    between consecutive transactions. If the available balance of a later transaction \n",
    "    is greater than the previous one (and the previous transaction is not a reversal or address verification), \n",
    "    a replenishment transaction is added synthetically.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing transaction data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with added synthetic replenishment transactions. \n",
    "    The output will be sorted by 'accountNumber' and 'transactionDateTime'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort data by account number and transaction datetime\n",
    "    df = df.sort_values(['accountNumber', 'transactionDateTime']).reset_index(drop=True)\n",
    "\n",
    "    # List to store new replenishment transactions\n",
    "    replenishments = []\n",
    "\n",
    "    # Group transactions by account number\n",
    "    grouped = df.groupby('accountNumber')\n",
    "\n",
    "    # Iterate over each account group\n",
    "    for account, group in grouped:\n",
    "        # Create a replenishment before the first transaction\n",
    "        first_transaction = group.iloc[0]\n",
    "        replenish_row = first_transaction.copy()\n",
    "        replenish_row['transactionDateTime'] = first_transaction['transactionDateTime'] - datetime.timedelta(days=1)\n",
    "        replenish_row['transactionAmount'] = first_transaction['creditLimit']\n",
    "        replenish_row['enteredCVV'] = first_transaction['cardCVV']\n",
    "        replenish_row['transactionType'] = 'REPLENISHMENT'\n",
    "        replenish_row['isFraud'] = False\n",
    "        replenishments.append(replenish_row)\n",
    "\n",
    "        # Process the rest of the transactions\n",
    "        for i in range(1, len(group)):\n",
    "            current_transaction = group.iloc[i]\n",
    "            previous_transaction = group.iloc[i - 1]\n",
    "\n",
    "            # Check if a replenishment is needed between transactions\n",
    "            if (current_transaction['availableMoney'] >= previous_transaction['availableMoney'] and\n",
    "                    previous_transaction['transactionAmount'] != 0 and\n",
    "                    previous_transaction['transactionType'] not in ['REVERSAL', 'ADDRESS_VERIFICATION']):\n",
    "                # Calculate the replenishment datetime\n",
    "                difference = current_transaction['transactionDateTime'] - previous_transaction['transactionDateTime']\n",
    "                replenishment_transaction_date_time = (\n",
    "                    current_transaction['transactionDateTime'] if difference <= datetime.timedelta(0)\n",
    "                    else current_transaction['transactionDateTime'] - difference / 2\n",
    "                )\n",
    "\n",
    "                # Create replenishment transaction\n",
    "                replenish_row = previous_transaction.copy()\n",
    "                replenish_row['transactionDateTime'] = replenishment_transaction_date_time\n",
    "                replenish_row['availableMoney'] = previous_transaction['availableMoney'] - previous_transaction[\n",
    "                    'transactionAmount']\n",
    "                replenish_row['creditDebt'] = previous_transaction['creditDebt'] + previous_transaction[\n",
    "                    'transactionAmount']\n",
    "                replenish_row['transactionAmount'] = current_transaction['availableMoney'] - replenish_row[\n",
    "                    'availableMoney']\n",
    "                replenish_row['enteredCVV'] = previous_transaction['cardCVV']\n",
    "                replenish_row['transactionType'] = 'REPLENISHMENT'\n",
    "                replenish_row['isFraud'] = False\n",
    "\n",
    "                # Append replenishment to the list\n",
    "                replenishments.append(replenish_row)\n",
    "\n",
    "    # Convert replenishments to DataFrame and merge with the original DataFrame\n",
    "    replenishment_df = pd.DataFrame(replenishments)\n",
    "    result_df = pd.concat([df, replenishment_df]).sort_values(['accountNumber', 'transactionDateTime']).reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Example call of the function\n",
    "df = stage_data_io_service.run_or_load_snapshot_data('add_skipped_replenishment_transactions', add_skipped_replenishment_transactions, df, False)\n"
   ],
   "id": "44d08fffc8f6660c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check dimension after adding new rows\n",
    "\n",
    "edaUtils.data_summary(df)"
   ],
   "id": "40ec5e00a7b82e50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Credit debt repayment stability ratio (CDRS Ratio)\n",
    "\n",
    "### Overview\n",
    "The primary goal of this analysis is to explore the relationship between a customer's spending and repayment patterns and the likelihood of fraudulent activity (`isFraud`). Specifically, we calculate a **stability coefficient** that reflects how consistently a customer closes their credit debt over time, then analyze how this coefficient correlates with fraud probability.\n",
    "\n",
    "### Key Variables\n",
    "\n",
    "1. **Spending Percentage**: The percentage of the credit limit that was spent between full debt repayments.\n",
    " $$ \\text{Spent Percentage} = \\left( \\frac{\\text{Total Amount Spent}}{\\text{Credit Limit}} \\right) \\times 100 $$\n",
    "\n",
    "2. **Days Between Resets**: The number of days between two consecutive events where the available balance equals the credit limit (i.e., the debt is fully repaid).\n",
    "\n",
    "### Stability ratio\n",
    "\n",
    "To measure customer stability, we consider two factors:\n",
    "- The **average spending percentage** between resets.\n",
    "- The **average number of days** between resets.\n",
    "\n",
    "These two values are normalized using Min-Max normalization to bring them into the range of [0, 1]. The final stability coefficient is computed as:\n",
    "\n",
    "$$ \\text{CDRS Ratio} = 1 - (\\text{Normalized Spending Percentage Between Resets} \\times \\text{Normalized Days Between Resets}) $$\n",
    "\n",
    "This coefficient ranges from 0 to 1, where:\n",
    "- A value closer to **1** indicates a more stable customer (less spending, more frequent repayments).\n",
    "- A value closer to **0** indicates less stable repayment behavior.\n",
    "\n",
    "### Hypothesis\n",
    "We hypothesize that a higher stability coefficient (more stable customers) correlates with a lower probability of fraudulent activity. Conversely, lower stability may indicate higher fraud risk.\n",
    "\n",
    "### Fraud Analysis\n",
    "Once the CDRS Ratio is calculated for each account, we group the accounts into ranges (bins) of stability coefficients and calculate the percentage of fraudulent transactions (`isFraud = True`) in each range. The results are visualized to test the hypothesis.\n",
    "\n",
    "### Conclusion\n",
    "This analysis can help identify patterns between customer behavior and fraud risk, providing valuable insights for improving fraud detection models.\n",
    "\n",
    "### Nice to fix and improve\n",
    "- Investigate anomaly in cdrs-ratio range from 0.222-0.333 -- 0.333-0.444\n",
    "- Improve scaling function (when size of input is 1)\n",
    "- Investigate and fix when normalized `avg_norm_days_between_resets` is NaN (reason might be in scaling function)\n"
   ],
   "id": "ce7d73856825add3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Function to visualize fraud percentage based on stability coefficient\n",
    "def visualize_fraud_vs_cdrs_ratio(fraud_stats):\n",
    "    \"\"\"\n",
    "    Visualizes the fraud percentage based on cdrs ratio ranges.\n",
    "\n",
    "    Parameters:\n",
    "    fraud_stats: DataFrame containing fraud statistics grouped by cdrs ratio ranges.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fraud_stats.index.astype(str), fraud_stats['fraud_percentage'], marker='o', linestyle='-', color='r')\n",
    "    plt.title('Fraud Percentage vs CDRS Ratio')\n",
    "    plt.xlabel('Credit debt repayment stability ratio Range')\n",
    "    plt.ylabel('Fraud Percentage')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_account_stability_stats(account, transactions, reset_indices, stability_data):\n",
    "    days_between_resets = []\n",
    "    spent_percentages = []\n",
    "    # Calculate the amount spent and days between credit limit resets\n",
    "    for i in range(1, len(reset_indices)):\n",
    "        start_idx = (reset_indices[i - 1]) + 1  # not include transaction of replenishment\n",
    "        end_idx = (reset_indices[i]) - 1  # not include transaction of replenishment\n",
    "\n",
    "        # Exclude replenishment transactions from the spending calculation\n",
    "        transaction_slice = transactions.loc[start_idx:end_idx]\n",
    "        non_replenishment_transactions = transaction_slice[\n",
    "            (transaction_slice['transactionType'] != 'REPLENISHMENT') &\n",
    "            (transaction_slice['transactionType'] != 'ADDRESS_VERIFICATION') &\n",
    "            (transaction_slice['transactionType'] != 'REVERSAL')\n",
    "            ]\n",
    "\n",
    "        # Calculate the total amount spent between resets\n",
    "        total_spent = non_replenishment_transactions['transactionAmount'].sum()\n",
    "        credit_limit = transactions.loc[start_idx, 'creditLimit']\n",
    "\n",
    "        spent_percentage = abs((total_spent / credit_limit) * 100)\n",
    "        spent_percentages.append(spent_percentage)\n",
    "\n",
    "        # Calculate the number of days between the two resets\n",
    "        start_date = transactions.loc[start_idx, 'transactionDateTime']\n",
    "        end_date = transactions.loc[end_idx, 'transactionDateTime']\n",
    "        days_between = (end_date - start_date).days\n",
    "        days_between_resets.append(days_between)\n",
    "\n",
    "    # Normalize spent percentages and days between resets\n",
    "    norm_spent_percentages = dtUtils.min_max_normalize(spent_percentages)\n",
    "    norm_days_between_resets = dtUtils.min_max_normalize(days_between_resets)\n",
    "    # Calculate the average normalized values\n",
    "    avg_norm_spent_percentage = np.mean(norm_spent_percentages)\n",
    "    avg_norm_days_between_resets = np.mean(norm_days_between_resets)\n",
    "    # Stability ratio: higher values mean the customer is more stable\n",
    "    cdrs_ratio = 1 - (avg_norm_spent_percentage * avg_norm_days_between_resets)\n",
    "    stability_data.append({\n",
    "        'accountNumber': account,\n",
    "        'creditLimit': transactions.iloc[0].creditLimit,\n",
    "        'avg_norm_spent_percentage': avg_norm_spent_percentage,\n",
    "        'avg_norm_days_between_resets': avg_norm_days_between_resets,\n",
    "        'cdrs_ratio': cdrs_ratio\n",
    "    })\n",
    "\n",
    "def calculate_fraud_stats(df, stability_stats):\n",
    "    # Merge with the original DataFrame on accountNumber\n",
    "    df_merged = df[['accountNumber', 'isFraud']].drop_duplicates().merge(stability_stats, on='accountNumber',\n",
    "                                                                         how='left')\n",
    "    # Create bins for stability coefficient ranges\n",
    "    df_merged['cdrs_range'] = pd.cut(df_merged['cdrs_ratio'], bins=np.linspace(0, 1, 10))\n",
    "    # Calculate fraud percentage in each stability coefficient range\n",
    "    fraud_stats = df_merged.groupby('cdrs_range').agg(\n",
    "        fraud_count=('isFraud', lambda x: (x == True).sum()),\n",
    "        total_count=('isFraud', 'count')\n",
    "    )\n",
    "    fraud_stats['fraud_percentage'] = (fraud_stats['fraud_count'] / fraud_stats['total_count']) * 100\n",
    "    return fraud_stats\n",
    "\n",
    "def calculate_cdrs_ratio(df, credit_cover_threshold):\n",
    "    \"\"\"\n",
    "    Calculates the credit debt repayment stability coefficient for each account and visualizes fraud probability based on the coefficient.\n",
    "\n",
    "    Parameters:\n",
    "    df: DataFrame containing transaction data for various accounts.\n",
    "    credit_cover_threshold (ex. 0.2, 0.7, 1): float, the percentage threshold for considering replenishment transactions to be included in \n",
    "    stability calculations. Only replenishment transactions that result in an available balance exceeding \n",
    "    credit_cover_threshold% of the credit limit will be considered.\n",
    "\n",
    "    Returns:\n",
    "    Updated DataFrame with stability coefficient added, and fraud statistics DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['accountNumber', 'transactionDateTime'])\n",
    "\n",
    "    stability_data = []\n",
    "\n",
    "    # Loop through each account and calculate stability coefficient\n",
    "    for account, transactions in df.groupby('accountNumber'):\n",
    "        transactions = transactions.reset_index(drop=True)\n",
    "\n",
    "        # Find indices where credit limit is reset (repaid based on the X percent threshold)\n",
    "        reset_indices = transactions[\n",
    "            (transactions['transactionType'] == 'REPLENISHMENT') &\n",
    "            ((transactions['transactionAmount'] + transactions['availableMoney']) >= transactions[\n",
    "                'creditLimit'] * credit_cover_threshold)\n",
    "            ].index.tolist()\n",
    "\n",
    "        if len(reset_indices) < 2:\n",
    "            continue  # Skip accounts with insufficient data for calculation. Ratio for these account will be predicted by other model\n",
    "\n",
    "        calculate_account_stability_stats(account, transactions, reset_indices, stability_data)\n",
    "\n",
    "    # Create DataFrame with stability coefficients for each account\n",
    "    stability_stats = pd.DataFrame(stability_data)\n",
    "\n",
    "    fraud_stats = calculate_fraud_stats(df, stability_stats)\n",
    "\n",
    "    # Add stability coefficient to the original DataFrame\n",
    "    df = df.merge(stability_stats, on='accountNumber', how='left')\n",
    "\n",
    "    return df, fraud_stats, stability_stats\n",
    "\n",
    "\n",
    "# Call the function to analyze and visualize\n",
    "df_with_stability, fraud_stats, tuned_stability_stats = calculate_cdrs_ratio(df, credit_cover_threshold=1)\n",
    "visualize_fraud_vs_cdrs_ratio(fraud_stats)"
   ],
   "id": "a8924ff0872e0c8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(df_with_stability)",
   "id": "825b519b3714c970"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predicting CDRS ratio for account with insufficient replenishments according to threshold\n",
   "id": "d3eb65a9d2205f31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "df = df.sort_values(['accountNumber', 'transactionDateTime'])\n",
    "\n",
    "\n",
    "def calculate_stability_stats_for_all_accounts(df):\n",
    "    stability_data = []\n",
    "    for account, transactions in df.groupby('accountNumber'):\n",
    "        transactions = transactions.reset_index(drop=True)\n",
    "\n",
    "        reset_indices = transactions[transactions['transactionType'] == 'REPLENISHMENT'].index.tolist()\n",
    "\n",
    "        if len(reset_indices) < 2:\n",
    "            reset_indices = [transactions.head(1).index.item(), transactions.tail(1).index.item()]\n",
    "\n",
    "        calculate_account_stability_stats(account, transactions, reset_indices, stability_data)\n",
    "    stability_stats_full = pd.DataFrame(stability_data)\n",
    "    stability_stats_full['cdrs_ratio'] = np.nan\n",
    "    merged_df = stability_stats_full[['accountNumber']].merge(\n",
    "        tuned_stability_stats[['accountNumber', 'cdrs_ratio']],\n",
    "        on='accountNumber',\n",
    "        how='left'\n",
    "    )\n",
    "    stability_stats_full['cdrs_ratio'] = merged_df['cdrs_ratio']\n",
    "    stability_stats_full['cdrs_range'] = pd.cut(stability_stats_full['cdrs_ratio'], bins=np.linspace(0, 1, 10))\n",
    "    return stability_stats_full\n",
    "\n",
    "\n",
    "stability_stats_full = stage_data_io_service.run_or_load_snapshot_data('add_skipped_replenishment_transactions', calculate_stability_stats_for_all_accounts, df, False)\n",
    "stability_stats_full\n"
   ],
   "id": "5be1a6096cfaa9d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "stability_stats_full.describe()",
   "id": "8ccfb62aec9a4fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(stability_stats_full)",
   "id": "3a7fe4fb0dba5db7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pltUtils.plot_correlation_heatmap(stability_stats_full, ['creditLimit', 'cdrs_ratio', 'avg_norm_days_between_resets', 'avg_norm_spent_percentage'], cmap=\"Reds\")",
   "id": "4976e15ed603cf35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "both_avg_stats_is_na_accounts = stability_stats_full[(stability_stats_full['avg_norm_days_between_resets'].isnull()) & (\n",
    "    stability_stats_full['avg_norm_spent_percentage'].isnull())]['accountNumber']\n",
    "stab_df_both_avg_stats_is_na_accounts = stability_stats_full[\n",
    "    stability_stats_full['accountNumber'].isin(both_avg_stats_is_na_accounts)]\n",
    "stab_df_both_avg_stats_is_na_accounts"
   ],
   "id": "17b9f2864fc0fbbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gen_df_with_both_invalid_avg_stats = df[df['accountNumber'].isin(both_avg_stats_is_na_accounts)]\n",
    "print(\n",
    "    f'Count of account transactions where both necessary params avg (spent percentage, avg days btw resets) is nan in stability stats: {gen_df_with_both_invalid_avg_stats.shape[0]}')\n",
    "edaUtils.calculate_percentage(gen_df_with_both_invalid_avg_stats.shape[0], df.shape[0])\n",
    "print(\n",
    "    f'Count of frauds transactions in gen dataset by these account numbers: {gen_df_with_both_invalid_avg_stats[gen_df_with_both_invalid_avg_stats[\"isFraud\"] == True].shape[0]}')"
   ],
   "id": "830bc342570104cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.drop(index=gen_df_with_both_invalid_avg_stats.index, inplace=True)\n",
    "stability_stats_full.drop(index=stab_df_both_avg_stats_is_na_accounts.index, inplace=True)\n",
    "edaUtils.data_summary(stability_stats_full)"
   ],
   "id": "b66301d118ddbb53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stab_df_invalid_spent_avg_stats_is_na_accounts = \\\n",
    "    stability_stats_full[stability_stats_full['avg_norm_spent_percentage'].isnull()]['accountNumber']\n",
    "gen_df_with_invalid_spent_avg_stats = df[df['accountNumber'].isin(stab_df_invalid_spent_avg_stats_is_na_accounts)]\n",
    "\n",
    "print(\n",
    "    f'Count of account transactions where avg spent percentage btw resets in nan in stability stats: {gen_df_with_invalid_spent_avg_stats.shape[0]}')\n",
    "edaUtils.calculate_percentage(gen_df_with_invalid_spent_avg_stats.shape[0], df.shape[0])\n",
    "print(\n",
    "    f'Count of frauds transactions in gen dataset by these account numbers: {gen_df_with_invalid_spent_avg_stats[gen_df_with_invalid_spent_avg_stats[\"isFraud\"] == True].shape[0]}')"
   ],
   "id": "6cb09108ced15b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[df['accountNumber'] == '259711806']",
   "id": "2a355cc0128bc7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.drop(index=gen_df_with_invalid_spent_avg_stats.index, inplace=True)\n",
    "stability_stats_full.drop(index=stab_df_invalid_spent_avg_stats_is_na_accounts.index, inplace=True)\n",
    "edaUtils.data_summary(stability_stats_full)"
   ],
   "id": "e02af108f3b7c5e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "days_avg_stat_is_na_accounts = stability_stats_full[stability_stats_full['avg_norm_days_between_resets'].isnull()][\n",
    "    'accountNumber']\n",
    "stab_df_days_avg_stats_is_na_accounts = stability_stats_full[\n",
    "    stability_stats_full['accountNumber'].isin(days_avg_stat_is_na_accounts)]\n",
    "stab_df_days_avg_stats_is_na_accounts"
   ],
   "id": "59535582ccaae728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gen_df_with_invalid_days_avg_stats = df[df['accountNumber'].isin(days_avg_stat_is_na_accounts)]\n",
    "print(\n",
    "    f'Count of account transactions where avg days btw resets in nan in stability stats: {gen_df_with_invalid_days_avg_stats.shape[0]}')\n",
    "edaUtils.calculate_percentage(gen_df_with_invalid_days_avg_stats.shape[0], df.shape[0])\n",
    "print(\n",
    "    f'Count of frauds transactions in gen dataset by these account numbers: {gen_df_with_invalid_days_avg_stats[gen_df_with_invalid_days_avg_stats[\"isFraud\"] == True].shape[0]}')\n",
    "\n",
    "edaUtils.calculate_percentage(gen_df_with_invalid_days_avg_stats[gen_df_with_invalid_days_avg_stats[\"isFraud\"] == True].shape[0],\n",
    "                              df[df['isFraud'] == True].shape[0])"
   ],
   "id": "3706abf92f9890d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[df['accountNumber'] == '155977598']",
   "id": "c6f1fda68b4a94d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.drop(index=gen_df_with_invalid_days_avg_stats.index, inplace=True)\n",
    "stability_stats_full.drop(index=stab_df_days_avg_stats_is_na_accounts.index, inplace=True)\n",
    "edaUtils.data_summary(stability_stats_full)"
   ],
   "id": "c354a09b937c1a5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cdrs_ratio_is_0_accounts = stability_stats_full[stability_stats_full['cdrs_ratio'] == 0]['accountNumber']\n",
    "stab_df_cdrs_ratio_is_0 = stability_stats_full[stability_stats_full['accountNumber'].isin(cdrs_ratio_is_0_accounts)]\n",
    "stab_df_cdrs_ratio_is_0"
   ],
   "id": "a3acbffbd96ec418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gen_df_cdrs_ratio_is_0 = df[df['accountNumber'].isin(cdrs_ratio_is_0_accounts)]\n",
    "print(f'Count of account transactions where cdrs ratio is 0 in stability stats: {gen_df_cdrs_ratio_is_0.shape[0]}')\n",
    "edaUtils.calculate_percentage(gen_df_cdrs_ratio_is_0.shape[0], df.shape[0])\n",
    "print(\n",
    "    f'Count of frauds transactions in gen dataset by these account numbers: {gen_df_cdrs_ratio_is_0[gen_df_cdrs_ratio_is_0[\"isFraud\"] == True].shape[0]}')\n",
    "\n",
    "edaUtils.calculate_percentage(gen_df_cdrs_ratio_is_0[gen_df_cdrs_ratio_is_0[\"isFraud\"] == True].shape[0],\n",
    "                              df[df['isFraud'] == True].shape[0])\n"
   ],
   "id": "e7bbbd4fd99fba0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.drop(index=gen_df_cdrs_ratio_is_0.index, inplace=True)\n",
    "stability_stats_full.drop(index=cdrs_ratio_is_0_accounts.index, inplace=True)\n",
    "edaUtils.data_summary(stability_stats_full)"
   ],
   "id": "dcd865a4be7a5a8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stability_stats_full_test_pred_df = stability_stats_full.copy()\n",
    "stability_stats_full_test_pred_df.dropna(inplace=True)\n",
    "cdrs_range_encoder = LabelEncoder()\n",
    "\n",
    "stability_stats_full_test_pred_df['cdrs_range_encoded'] = cdrs_range_encoder.fit_transform(\n",
    "    stability_stats_full_test_pred_df['cdrs_range'])\n",
    "edaUtils.data_summary(stability_stats_full_test_pred_df)\n"
   ],
   "id": "479e2f959e5683bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_stats_full = stability_stats_full_test_pred_df.drop(\n",
    "    columns=['cdrs_range', 'cdrs_range_encoded', 'cdrs_ratio', 'accountNumber'])\n",
    "Y_stats_full = stability_stats_full_test_pred_df['cdrs_range_encoded']\n",
    "\n",
    "X_stats_full_train, X_stats_full_test, Y_stats_full_train, Y_stats_full_test = train_test_split(X_stats_full,\n",
    "                                                                                                Y_stats_full,\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                random_state=101)"
   ],
   "id": "954e128e47493de8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cdrs_range_encoded_weights = compute_class_weight('balanced', classes=Y_stats_full_train.unique(), y=Y_stats_full_train)\n",
    "print(f'Cdrs range distribution weights in train dataset {cdrs_range_encoded_weights}')"
   ],
   "id": "51223d39eb443cc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example of how to use these functions\n",
    "# Assume models_dict is defined with the models and parameters you want to tune\n",
    "cdrs_range_best_model = mteUtils.load_or_tune_and_evaluate_models('cdrs_ratio_predictor', mteUtils.models_dictionary, X_stats_full_train, X_stats_full_test, Y_stats_full_train, Y_stats_full_test, re_train=False)"
   ],
   "id": "536d69517c82966"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pltUtils.plot_confusion_matrix_model(cdrs_range_best_model, X_stats_full_test, Y_stats_full_test)\n",
    "pltUtils.plot_feature_importance(cdrs_range_best_model, X_stats_full_train.columns)"
   ],
   "id": "5378049ac60a08e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(stability_stats_full)",
   "id": "77a8e455520e2384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "empty_cdrs_ratio_accounts = stability_stats_full[stability_stats_full['cdrs_range'].isnull()]\n",
    "data_for_cdrs_range_prediction = empty_cdrs_ratio_accounts.drop(columns=['cdrs_ratio', 'cdrs_range', 'accountNumber'])\n",
    "encoded_predicted_cdrs_range = cdrs_range_best_model.predict(data_for_cdrs_range_prediction)\n",
    "empty_cdrs_ratio_accounts['cdrs_range'] = cdrs_range_encoder.inverse_transform(encoded_predicted_cdrs_range)\n",
    "\n",
    "mean_cdrs_ratio_per_range = stability_stats_full[stability_stats_full['cdrs_range'].notna()].groupby('cdrs_range')['cdrs_ratio'].mean()\n",
    "def fill_na_with_mean(row):\n",
    "    if pd.isna(row['cdrs_ratio']):\n",
    "        return mean_cdrs_ratio_per_range[row['cdrs_range']]\n",
    "    else:\n",
    "        return row['cdrs_ratio']\n",
    "\n",
    "empty_cdrs_ratio_accounts['cdrs_ratio'] = empty_cdrs_ratio_accounts.apply(fill_na_with_mean, axis=1)\n",
    "\n",
    "stability_stats_full.loc[\n",
    "    stability_stats_full['accountNumber'].isin(empty_cdrs_ratio_accounts['accountNumber']),\n",
    "    ['cdrs_range', 'cdrs_ratio']\n",
    "] = empty_cdrs_ratio_accounts[['cdrs_range', 'cdrs_ratio']].values\n",
    "\n",
    "stability_stats_full\n"
   ],
   "id": "2b396c2ebd1eca2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(stability_stats_full)",
   "id": "acf53c9cca6fe0ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "visualize_fraud_vs_cdrs_ratio(calculate_fraud_stats(df, stability_stats_full))",
   "id": "67f297d7ccf4cbac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Add cdrs ratio and range to general dataset and drop synthetic replenishment transactions",
   "id": "1b4ed3d257e86d41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cdrs_ratio_data = stability_stats_full[['accountNumber', 'cdrs_ratio', 'cdrs_range']]\n",
    "df = df.merge(cdrs_ratio_data, on='accountNumber', how='left')\n",
    "df = df[df['transactionType'] != 'REPLENISHMENT']\n",
    "df.head()"
   ],
   "id": "286a3615940218f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(df)",
   "id": "c9ce507dcfcc4fe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating a new feature (MATCH ENTERED CVV OR NOT)",
   "id": "5822c5b313c463ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['cvv_matched_status'] = [True if actual_cvv == entered_cvv else False for actual_cvv, entered_cvv in zip(df['cardCVV'], df['enteredCVV'])]\n",
    "df.drop(columns=['cardCVV', 'enteredCVV'], inplace=True)\n",
    "edaUtils.data_summary(df)"
   ],
   "id": "ee5b957c7233fa45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating a new feature (Address change count)",
   "id": "20dc334667c059e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_address_change_count_column(df):\n",
    "    \"\"\"\n",
    "    Adds a new column 'addressChangeCount' to the DataFrame with the number of address changes\n",
    "    per account up to the time of each transaction.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset containing transactions.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated DataFrame with the new 'addressChangeCount' column.\n",
    "    \"\"\"\n",
    "    # Convert columns with dates to datetime format\n",
    "    df['dateOfLastAddressChange'] = pd.to_datetime(df['dateOfLastAddressChange'])\n",
    "    df['transactionDateTime'] = pd.to_datetime(df['transactionDateTime'])\n",
    "\n",
    "    # Sort by accountNumber and transactionDateTime to ensure correct order\n",
    "    df = df.sort_values(by=['accountNumber', 'transactionDateTime'])\n",
    "\n",
    "    # Initialize a new column for address change count\n",
    "    df['addressChangeCount'] = 0\n",
    "\n",
    "    # Group by account number to process each account's transactions individually\n",
    "    for account, group in df.groupby('accountNumber'):\n",
    "        address_changes = 0\n",
    "        last_change_date = None\n",
    "\n",
    "        # Iterate through each transaction for the account\n",
    "        for idx, row in group.iterrows():\n",
    "            # Check if the current transaction date is after the last address change\n",
    "            if last_change_date is None or row['dateOfLastAddressChange'] > last_change_date:\n",
    "                address_changes += 1\n",
    "                last_change_date = row['dateOfLastAddressChange']\n",
    "\n",
    "            # Set the count of address changes up to the current transaction\n",
    "            df.at[idx, 'addressChangeCount'] = address_changes - 1\n",
    "\n",
    "    return df"
   ],
   "id": "a00121aa83655d4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = add_address_change_count_column(df)",
   "id": "ac3cef2b639256d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "edaUtils.data_summary(df)",
   "id": "4e6f3cdaaefd980b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_suspicious_transactions(df, time_threshold_milliseconds):\n",
    "    \"\"\"\n",
    "    Identify suspicious transactions within a specified time threshold.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The transaction dataset, which includes 'accountNumber', 'transactionDateTime', and 'transactionAmount'.\n",
    "    time_threshold_milliseconds (int): The time window in milliseconds within which multiple transactions of the same amount are flagged as suspicious.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an additional 'is_suspicious' column.\n",
    "    \"\"\"\n",
    "    # Sort by 'accountNumber' and 'transactionDateTime' to arrange transactions chronologically by account\n",
    "    df = df.sort_values(['accountNumber', 'transactionDateTime']).reset_index(drop=True)\n",
    "    \n",
    "    # Check for duplicate transaction amounts for each account using `transform` to maintain DataFrame shape\n",
    "    is_duplicate_amount = df.groupby('accountNumber')['transactionAmount'].transform(lambda x: x.duplicated())\n",
    "    \n",
    "    # Calculate time difference between consecutive transactions for each account in milliseconds\n",
    "    is_within_time_threshold = df.groupby('accountNumber')['transactionDateTime'].diff() <= pd.Timedelta(time_threshold_milliseconds, unit='milliseconds')\n",
    "    \n",
    "    # Combine conditions: duplicate amount and time difference within threshold\n",
    "    df[\"is_suspicious\"] = is_duplicate_amount & is_within_time_threshold\n",
    "    \n",
    "    return df"
   ],
   "id": "980e9ca9d0463ace"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = find_suspicious_transactions(df, time_threshold_milliseconds=3 * 60 * 1000)\n",
    "suspicious_df = df[df['is_suspicious'] == True]\n",
    "\n",
    "print(\"Total number of suspicious transactions: {}\".format(suspicious_df.shape[0]))\n",
    "print(\"Total transaction amount of suspicious transactions: {}$\".format(round(suspicious_df['transactionAmount'].sum(), 2)))\n",
    "edaUtils.data_summary(df)"
   ],
   "id": "362cb80a4d953c88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing df for Model building",
   "id": "c02c6de558519d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fraud_modelling_df = df.drop(columns=[\n",
    "    'accountNumber',\n",
    "    'transactionDateTime',\n",
    "    'currentExpDate',\n",
    "    'accountOpenDate',\n",
    "    'dateOfLastAddressChange'\n",
    "])\n",
    "fraud_modelling_df.columns"
   ],
   "id": "46d5309e1184575e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fraud_modelling_df, encoders = dtUtils.encode_categorical_columns(fraud_modelling_df, [\n",
    "    'acqCountry', 'merchantCountryCode', 'posEntryMode', 'posConditionCode', 'merchantCategoryCode', 'transactionType', 'creditLimitRange', 'cdrs_range'\n",
    "])"
   ],
   "id": "44891f303eeaa80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fraud_modelling_df = dtUtils.convert_bool_columns_to_int(fraud_modelling_df, ['cardPresent', 'expirationDateKeyInMatch', 'isFraud', 'cvv_matched_status', 'is_suspicious'])",
   "id": "77d6eaa7193fb3ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pltUtils.plot_barplot_distribution(fraud_modelling_df, fraud_modelling_df['isFraud'], 'Transaction Count by isFraud Value (without sampling)')",
   "id": "9ec7d8e1b5109c97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sampled_modelling_df = dtUtils.sample_data(fraud_modelling_df, 'isFraud', method='undersample')",
   "id": "63f4aeacffd10fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pltUtils.plot_barplot_distribution(sampled_modelling_df, sampled_modelling_df['isFraud'], 'Transaction Count by isFraud Value (after undersampling)')",
   "id": "aae04f1c6dc2ea80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "stage_data_io_service.write_stage_data(df)",
   "id": "6840eb8805b0193c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "642c5db9528f3353"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
